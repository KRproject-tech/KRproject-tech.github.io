<!DOCTYPE html>
<html lang="ja">
<head prefix="og: http://ogp.me/ns# fb: http://ogp.me/ns/fb# article: http://ogp.me/ns/article#">
	
  <meta charset="utf-8">
  <title>Efficient Rolling Motion for Snake-like Robots Utilizing a COG Shift</title>	
	
  <link rel="stylesheet" href="../css/style_variables.css">
  <link rel="stylesheet" href="../css/style_cms.css">
  <link rel="stylesheet" href="../css/font-awesome.min.css">
  <link rel="stylesheet" href="../css/style.css">
  
</head>

<body class="color__site nav-top ">  

  <main class="contents">
    <div class="sidescroll"></div>
    <div class="pblock">
      <h1 class="ttl__style00">
        <span class="ptitle__title">Deep Reinforcement Learning-based Design of Rolling Motion for Snake-like Robots</span>
      </h1>


<div class="editor__main">
          <div>

<p style="text-align: center;"><a href="./3Ddata/index.html" title="3D view" class="linkhover" target="_blank" rel="noopener"><img alt="rolling_mode_SIDE_2" style="text-align: center; display: block; margin: 0 auto 20px;" src="../../assets/XFMV-9KM_rolling_mode_SIDE.jpg" width="2672" height="957"></a>3D view</p>
<p style="text-align: center;"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZmoQswbGZXU" title="Reinforcement learning of Rolling Motion" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2 class="ttl__style01">Abstract</h2>
<h2 class="ttl__style01"></h2>
<p style="text-align: justify;">Snake-like robots have higher mobility than wheeled robots. However, there is an issue of increased power consumption when they reproduce the undulating locomotion like biological snakes because of a lot of servomotors driving on joints. We propose an efficient method that integrates the center-of-gravity (COG) shifting for the navigation of the robot to address the aforementioned problem. In the proposed method, a snake-like robot is transformed into the shape of a tire to realize the parallel two-wheeled vehicle, and the COG is changed by deforming the links to generate a rolling motion. This implementation allows for the choice between rolling and undulating locomotion depending on whether the level or rough ground. Previous research has used gravity data from an acceleration sensor as feedback, but this has led to problems with maintaining straight-line stability when road conditions change. This paper presents a controller design method using deep reinforcement learning (RL) to achieve robust traveling by the rolling motion.</p>
<p><span></span></p>
<h2 class="ttl__style01">Experimental setup</h2>
<details>
<summary>Details</summary>
<ol></ol>
<p style="text-align: justify;">Except for the body link equipped with an inertial measurement unit (IMU) and a single-board computer (SBC), the structure is the same as that of <a href="https://doi.org/10.1016/j.mechatronics.2023.103024" class="linkhover" target="_blank" rel="noopener">previous studies (Yamano et al., 2023)</a>. The proposed robot can switch between undulation and rolling motion, and it can also serve as a method for appropriate rolling motion by COG shift. The rolling motion is generated by COG shift with the transformation of multi-links, and this mode achieves high traveling efficiency on level ground.</p>
<p style="text-align: justify;"><img alt="link_detail_9KM_control_structure_9KM" style="text-align: center; display: block; margin: 0 auto 20px;" src="../../assets/link_detail_9KM_control_structure_9KM.jpg" width="1683" height="1827"></p>
</details>
<h2 class="ttl__style01">Controller design by deep reinforcement learning</h2>
<details>
<summary>Details</summary>
<ol></ol>
<p style="text-align: justify;">We employ the Soft Actor Critic (SAC), which is one of the off-policy deep reinforcement learning algorithms, to design the improved controller for the rolling motion of the snake-like robot. Here, we employ the Stable Baselines3 (SB3, v2.4.1) as the reinforcement learning environment. Schematic diagrams of the overall reinforcement learning (RL) framework with SAC for training in simulation and deployment are shown in the figure below. 
The policy learned by the simulation by the Genesis is transferred to the SBC on the snake-like robot for the experiment.
</p>
<p style="text-align: justify;"><img alt="RL_Training_and_Deployment" style="text-align: center; display: block; margin: 0 auto 20px;" src="../../assets/RL_Training_and_Deployment.jpg" width="2760" height="1529"></p>
</details>
<h2 class="ttl__style01">Demonstration movie</h2>
<p style="text-align: center;">
	<iframe width="283" height="530" src="https://www.youtube.com/embed/NQZAq0pEn4U" title="Deep Reinforcement Learning designüêç" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe> 
	<iframe width="283" height="530" src="https://www.youtube.com/embed/dWHV0zmK-9E" title="Rolling motion designed by the Deep Reinforcement Learning #robotics" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="allowfullscreen"></iframe>
	<iframe width="283" height="530" src="https://www.youtube.com/embed/wrr6ZCzC-aI" title="indoor outdoor test" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></p>
<h2 class="ttl__style01">References</h2>
<ol>
<li><a href="https://doi.org/10.23919/ICCAS66577.2025.11301120" title="ICCAS2025" class="linkhover" target="_blank" rel="noopener">Satomi Suzuki, Akio Yamano, Tsuyoshi Kimoto, and Takashi Iwasa, Study on the Rolling Motion of a Snake-Like Robot That Transforms into a Parallel Two-Wheeled Vehicle Using Deep Reinforcement Learning, The 25th International Conference on Control, Automation and Systems (ICCAS 2025), Incheon, Korea, 2025. </a></li>
</ol>
<h2 class="ttl__style01">Related Publications</h2>
<ol>
<li><a href="https://doi.org/10.1016/j.robot.2026.105370" title="RAS" class="linkhover" target="_blank" rel="noopener">A. Yamano, S. Satomi, T. Kimoto, and T. Iwasa, Deep reinforcement learning-based design with observation buffer of rolling motion for snake-like robots, Robotics and Autonomous Systems, accepted (2026).</a><strong><a href="https://dx.doi.org/10.2139/ssrn.5875221" title="SSRN" class="linkhover" target="_blank" rel="noopener">[Preprint: Open access]</a></strong></li>
</ol>
<p><span></span></p>
<h2 class="ttl__style01"><span>Grants</span></h2>
<ol>
<li><a href="https://kaken.nii.ac.jp/ja/grant/KAKENHI-PROJECT-25K07667/" title="KibanC" class="linkhover" target="_blank" rel="noopener">JSPS, Grant-in-Aid for Scientific Research (C), 25K07667, 2025-2029.</a></li>
<li><a href="https://mzaidan.mazda.co.jp/results/science_serach/2020.html" title="MAZUDA" class="linkhover" target="_blank" rel="noopener">MAZUDA Foundation, 36th (2020) Mazda Research Grant, 2020-2022.</a></li>
</ol>
          </div>
          <div class="mt-30">
            
          </div>

          <!-- SNS-Share[Facebook,Twitter,Line] -->
          
            <ul class="ft__sns-list ft__sns-list_wrap my-30">
              
                <li class="ft__sns-item"><a class="ft__sns-link ft__sns-link_facebook noicon" href="https://www.facebook.com/sharer/sharer.php?u=https://www.omu.ac.jp/eng/iwasa/yamano/research_2/index.html" target="_blank" rel="noopener noreferrer">Facebook„Åß„Ç∑„Çß„Ç¢<!--<img src="/small_site/assets/ico_facebook.svg" alt="facebook">--></a></li>
              
              
                <li class="ft__sns-item"><a class="ft__sns-link ft__sns-link_twitter noicon" href="https://twitter.com/share?url=https://www.omu.ac.jp/eng/iwasa/yamano/research_2/index.html" target="_blank" rel="noopener noreferrer">Twitter„Åß„Ç∑„Çß„Ç¢<!--<img src="/small_site/assets/ico_twitter.svg" alt="Twitter">--></a></li>
              
              
                <li class="ft__sns-item"><a class="ft__sns-link ft__sns-link_line noicon" href="https://social-plugins.line.me/lineit/share?url=https://www.omu.ac.jp/eng/iwasa/yamano/research_2/index.html" target="_blank" rel="noopener noreferrer">LINE„Åß„Ç∑„Çß„Ç¢<!--<img src="/small_site/assets/ico_line.svg" alt="LINE">--></a></li>
              
            </ul>
          

        
      </div>
    </div>
  </main>
  
<div id="pagetop"><a Href = "#" onclick="location.href = '../index.html'" ><i class="fas fa-angle-up"></i></a></div>

</body>
</html>
